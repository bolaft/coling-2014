
% -----------------------------------------------------------------------------
\section{Building the segmenter}

We choose to define the segmentation problem as a sequence labelling task whose principle is to assign the globally best set of labels for the entire sequence of sentences at once. The underlying idea is that
the choice of the optimal label for a given sentence is dependent on the choices of nearby sentences. If a sentence is labelled \texttt{\footnotesize ending}, the next one should probably be  \texttt{\footnotesize starting}.

% wikipedia is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. A common example of a sequence labeling task is part of speech tagging, which seeks to assign a part of speech to each word in an input sentence or document. Sequence labeling can be treated as a set of independent classification tasks, one per member of the sequence. However, accuracy is generally improved by making the optimal label for a given element dependent on the choices of nearby elements, using special algorithms to choose the globally best set of labels for the entire sequence at once. 

Our email segmenter is built around a linear-chain Conditional Random Field (CRF) classifier, as implemented in the sequence labelling toolkit Wapiti \cite{lavergne2010practical}. Each email is processed as a sequence of sentences.

For the purposes of analysis and experimentation, we distinguish four sets of features: information structure based features, $n$-gram features, stylistic features and thematic features.
Several of them are borrowed from related work in speech act classification \cite{qadir2011classifying} and email segmentation \cite{lampert2009segmenting}. All the features are domain-independant. Almost all features are language-independant as well, save for a few that can be easily translated.


% -----------------------------------------------------------------------------
\subsection{Information structure based features}

This feature set is inspired by the information structure theory \cite{kruijff:1996} which 
describes the information imparted by the sentence in terms of the way it is related to prior context: topic, (back)ground, focus, new information\ldots The theory relates these functions with particular syntactic constructions (e.g. topicalization) and word order constraints in the sentence.
%
For languages such as English or French, the beginning of the sentence is an important position to structure the information at the discourse level while the ending of the sentence may carry information to announce what the following will deal with.
%The beginning of a sentence is so often seen as playing an important role in discourse structure 

We focus on the first and last three \textit{significant} tokens in the sentence. %, which often serve as connectors to adjoining sentences and therefore hold important structural information.
A token was determined as significant if its frequency was higher than  1/2000.
%Token significance is determined by the number of occurrences of the token in the training corpus: terms with a frequency lower than 1/2000 are considered insignificant. If a sentence contains less than six significant tokens, the same token can be found in both triplets. If the sentence contains less than three significant tokens, missing values are replaced by a placeholder.
As features we use $n$-grams of the form, lemma and part-of-speech tag of each triplet. For instance, from the sentence "\textit{Many thanks to all of you for the help you have offered, I have learned tremendously from all your suggestions.}", we generate the following features~: \texttt{\footnotesize Many/many/JJ/thanks/ thanks/NNS/to/to/TO/.../Many thanks/many thanks/JJ NNS/thanks to ./thanks to ./NNS TO ./\ldots}
%
%We define three individual features for each of the three unigrams, the two bigrams and the single trigram found in each of these triplets. The features are the following: the unaltered form of each token (case-sensitive), their lemmatized form (case-insensitive) and their corresponding part-of-speech. This is illustrated in figure ~\ref{fig:exampleSyntacticFeatures}.
%
We use the Stanford Log-linear Part-Of-Speech Tagger for morpho-syntactic tagging \cite{toutanova2003feature}, and the WordNet lexical database for performing the lemmatization \cite{miller1995wordnet}.

%\begin{figure}\small\centering
%\begin{tabular}{*{2}{|l}|l|}
%\toprule
%\textbf{Surface form} & \textbf{Lemma} & \textbf{P.O.S.}\\
%	\midrule
%	Many & many & JJ\\
%	thanks & thanks & NNS\\
%	to & to & TO\\
%	your & your & PRP\\
%	suggestions & suggestion & DD\\
%	. & . & .\\
%	Many thanks & many thanks & JJ NNS\\
%	thanks to . & thanks to . & NNS TO . \\
%	your suggestions & your suggestion & PRP DD\\
%	suggestions & suggestion & DD\\
%	Many thanks to & many thanks to & JJ NNS TO\\
%	your suggestions . & your suggestion . & PRP DD .\\
%	\bottomrule
%\end{tabular}

%\caption{Syntactic features formed from the sentence "\textit{Many thanks to all of you for the help you have offered, I have learned tremendously from all your suggestions.}" Each cell is a feature.}
%\label{fig:exampleSyntacticFeatures}
%\end{figure}

% -----------------------------------------------------------------------------
\subsection{$n$-gram features}

We select the 1000 bigrams and trigrams with the highest document frequency in the training data, and check for their presence in each sentence. Since the probability of having multiple occurrences of the same n-gram in one sentence are extremely low, we do not record the number of occurrences but merely a boolean value. The check is case-insensitive.

% -----------------------------------------------------------------------------
\subsection{Stylistic features}

Stylistic features include graphic, orthographic and semantic features. \textbf{Graphic features} capture information about the visual structure and composition of the message:

\begin{itemize}
	\item the position of the sentence in the email
	\item the average length of a token
	\item the total number of tokens
	\item the total number of characters
	\item the proportion of uppercase, alphabetic and numeric characters
\end{itemize}

\textbf{Orthographic features} capture information about the use of distinctive characters or character sequences:

\begin{itemize}
	\item the number of greater-than signs (``>''), also know as ``chevron'' symbols, in the sentence
	\item whether the sentence ends with a question mark, a colon or a semicolon, or if it at least contains one (three features)
	\item whether the sentence contains any punctuation within the first three tokens (this is meant to recognize greetings \cite{qadir2011classifying})
\end{itemize}

\textbf{Semantic features} check for meaningful words and phrases:

\begin{itemize}
	\item whether the sentence begins with a ``wh*'' question word  (\textit{``who''}, \textit{``when''}, \textit{``where''}, \textit{``what''}, \textit{``which''}, \textit{``what''}, \textit{``how''}) or an n-gram suggesting an incoming interrogation (e.g. \textit{``is it''} or \textit{``are there''}), and whether the sentence merely contains such a word or n-gram
	\item whether the sentence contains a modal (\textit{``may''}, \textit{``must''}, \textit{``shall''}, \textit{``will''}, \textit{``might''}, \textit{``should''}, \textit{``would''}, \textit{``could''}, and their negative forms)
	\item whether any plan phrases (e.g. \textit{``i will''} or \textit{``we are going to''}) are present
	\item whether the sentence contains first person, second person or third persons words (e.g. \textit{``we''}, \textit{``my''} and \textit{``me''} are recognized as first person words)
	\item the first personal pronoun found in the sentence
	\item the first verbal form found in the sentence as classified by the Stanford Part-Of-Speech tagger ; that is an element of the Penn Treebank tag set \footnote{Alphabetical list of part-of-speech tags used in the Penn Treebank Project: \url{http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html}} (e.g. the feature \textit{``VBZ''} indicates a present tense verb in third person singular)
\end{itemize}

\subsection{Thematic features}

The only feature we use to account for thematic shift recognition is the output of the Text Tiling algorithm \cite{hearst1997texttiling}. Text Tiling is one of the most commonly used algorithms for automatic text segmentation. It is a statistical method for thematic segmentation, i.e. a method that attempts to segment texts according to the contrasting themes of its parts: if the algorithm detects a rupture in the thematic continuity of the text, it will place a boundary to indicate a thematic change. This method is based on the notion of lexical cohesion.

\subsection{Labels}

Training the classifier to recognize the different labels of the previously defined annotation scheme can be problematic. It has indeed some disadvantages that can undermine the effectiveness of the classifier. In particular, sentences annotated \textit{SE} will, by definition, share important characteristics with sentences bearing the annotation \textit{S} and \textit{E}. For the purposes of segmentation, we chose to transform these annotations into a binary scheme and merely differentiate sentences that starts a new segment (\textit{True}), or "boundary sentences", from those that do not (\textit{False}). The conversion process is trivial, and can easily be reversed:

\begin{itemize}
    \item \textit{SE} $\longrightarrow$ \textit{True} $\longrightarrow$ \textit{SE} (if the next sentence is also a boundary)
    \item \textit{S} $\longrightarrow$ \textit{True} $\longrightarrow$ \textit{S} (if the next sentence is not a boundary)
    \item \textit{I} $\longrightarrow$ \textit{False} $\longrightarrow$ \textit{I} (if the next sentence is not a boundary either)
    \item \textit{E} $\longrightarrow$ \textit{False} $\longrightarrow$ \textit{E} (if the next sentence is a boundary)
\end{itemize}
