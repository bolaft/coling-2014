
%------------------------------------------------------------------------------
\section{Building annotated corpora of segmented online discussions at no cost}
\label{}

\begin{figure}
%\begin{quote}
%
%\singlespacing%
\small
[Hi ubuntu-ers,]$^{S1}$\vspace{0.1cm}

[I'm in need of some directions.]$^{S2}$ [I want to run ubuntu for my desktop,\\
but the installer doesn't support root or boot on raid.]$^{S3}$  \vspace{0.1cm}

[It seems that there must be a way to convert to raid after the fact, as\\
I've seen for some other distros.]$^{S4}$\vspace{0.1cm}

[I've tried a couple of the other distro specific directions, and just\\
wind up with a kernel panic.]$^{S5}$  \vspace{0.1cm}

[Are there some ubuntu specific instructions or advice?]$^{S6}$  [Thanks.]$^{S7}$\vspace{0.1cm}

-- \\ \ 
[Regards,]$^{S8}$ \\ \ 
[John]$^{S9}$
%Rich
%\end{quote}
\caption{}
\label{}
\end{figure}

\begin{figure}
%\begin{quote}
%
%\singlespacing
\small
[On Sun, 04 Dec 2005 15:45:13 -0600, John Doe\\
%On Sun, 05 Dec 2004 16:48:14 -0600, Rich Duzenbury
%<rduz-ubuntu@theduz.com> wrote:
<john@doe.com> wrote:]$^{R1}$\vspace{0.1cm}

> [I'm in need of some directions.]$^{R2}$  [I want to run ubuntu for my desktop,\\
> but the installer doesn't support root or boot on raid.]$^{R3}$\vspace{0.1cm}

[It claims not to. It actually does work.]$^{R4}$\vspace{0.1cm}

[Create a separate /boot partition for the kernel and initrd to live in\\
and then install to a / filesystem living on a RAID1 or RAID0 device\\
that you create during the install.]$^{R5}$ [My ubuntu server in the office\\
currently has 4 active disks doing RAID0+1 and running LVM on top with\\
another disk about to go in in case 2 happen to fail in quick\\
succession :-)]$^{R6}$\vspace{0.1cm}

> [It seems that there must be a way to convert to raid after the fact, as\\
> I've seen for some other distros.]$^{R7}$\vspace{0.1cm}

[It's also possible to convert after the fact using generic\\
instructions and rebuilding the initrd to cope with the fact that it\\
will need to run mdadm for you.]$^{R8}$\vspace{0.1cm}

[Cheers,]$^{R9}$\vspace{0.1cm}

[Bob.]$^{R10}$\vspace{0.1cm}
%Jon.

[P.S.]$^{R11}$ [This is a major sticking point for ubuntu and Debian acceptance\\
on mission critical kit which should be addressed.]$^{R12}$ [It's not too tricky\\
to boot and initrd off a separate boot partition.]$^{R13}$\vspace{0.1cm}
%\end{quote}
\caption{}
\label{}
\end{figure}


\begin{lstlisting}
Hi ubuntu-ers,

I'm in need of some directions.  I want to run ubuntu for my desktop,
but the installer doesn't support root or boot on raid.  

It seems that there must be a way to convert to raid after the fact, as
I've seen for some other distros.

I've tried a couple of the other distro specific directions, and just
wind up with a kernel panic.  

Are there some ubuntu specific instructions or advice?  Thanks.

--
Regards,
Rich

\end{lstlisting}




\begin{figure}
\begin{multicols}{2}
%\begin{twocolumn}
%\begin{figure}

\begin{rhetoricaltext} \footnotesize
\unit[1]{Hi ubuntu-ers,} 
%\\

\unit[2]{I'm in need of some directions.} 
\unit[3]{I want to run ubuntu for my desktop, \\
but the installer doesn't support root or boot on raid.  } \\ %voté de façon dispersée. }
\unit[5]{En rétorsion à ce résultat, les États-Unis, [\ldots]}  \\ %qui ont voté contre, ont annoncé...} 
%\unit[6]{Le Canada [\ldots] } %pourrait lui aussi  }
\unit[7]{De son côté, Israël [\ldots] } \\ %a fait part de...} 
\unit[8]{Cette adhésion intervient alors que l'État de Palestine tente d'être reconnu membre à part entière de l'ONU, 
et que le Conseil de sécurité des Nations unies étudie cette demande. } \\
\unit[9]{Devenir membre de l'UNESCO est %généralement 
perçu comme un signe positif dans une campagne d'adhésion aux Nations unies. } 
\source{fr.wikinews.org}%\footnote{\url{http://fr.wikinews.org/wiki/L\%27UNESCO_vote_l\%27adh\%C3\%A9sion_de_la_Palestine}}
\end{rhetoricaltext}
%\end{figure}
\\ Figure 1.1 : texte écrit en français
\newpage
%\begin{figure}
\begin{rhetoricaltext} \footnotesize
\unit[10]{UNESCO decided in a meeting of its General Council in Paris on Monday to admit Palestine as a full member.}\\
\unit[11]{107 votes approved entry, 14 opposed, and 52 abstained.}\\
\unit[12]{The move coincides with the Palestinians' bid for full membership in the United Nations. }\\
\unit[13]{The United Nations Security Council is currently reviewing the application. }\\
\unit[14]{Becoming a member of UNESCO is generally perceived as having a positive impact on all of its future bids.}
\source{en.wikinews.org}%\footnote{\url{http://en.wikinews.org/wiki/UNESCO_votes_in_favor_of_Palestine_membership}}
\end{rhetoricaltext}
%\end{figure}
\\Figure 1.2 :  texte écrit en anglais
\end{multicols}
\begin{center}
%\begin{figure}
%\begin{figure}
%{\hspace{30pt}\setlength{\compressionWidth}{160pt}
\multirel{Joint}{
	{\dirrel{}{{\rstsegment{\refr{1}}}}
		{Elaboration}{\rstsegment{\refr{2}}}
		{\hspace{3cm} Elaboration}{
			\multirel{Contrast}{
				{\rstsegment{\refr{3}\hspace{0,5cm}}   }
				%{\rstsegment{\refr{4}\hspace{0,5cm}}}
				{\rstsegment{\refr{5}\hspace{0,5cm}}}
				{\rstsegment{\refr{7}} }
			}
		}
	}
	{\rstsegment{\refr{8}\hspace{0,5cm}}}
	{\rstsegment{\refr{9}}}
}
\\Figure 1.3 :  structure rhétorique du texte de la figure 1.1
%}
%\raisebox{-2em}{}  \hspace{4cm}
%\caption{default}
%\label{fig:figure2}
%\end{figure}
%\end{figure}
\end{center}
%\end{twocolumn}
%\onecolumn
\caption{Extraits d'un article écrit en français mis en correspondance avec un article écrit en anglais et structure rhétorique du texte français}
\label{ExtraitsMisEnCorrespondance}
\end{figure}
%------------------------------------------------------------------------------
\subsection{Generate the annotations}
\label{}

The basic idea is to take benefit from the act of inserting new content at some specific position in a message initially uttered by a distinct person.
Assumptions in terms of relevance or role in the discourse organisation can be expressed on the new content, on the quoted text or even on the text which is not reused in the reply message.

In this paper, we choose to assume that the sentences of the quoted text in a reply message can inform

The original message consists in an homogeneous discourse flow of utterances. 

By replying to a message and by extracting deliberately some parts\footnote{Summarization operations are also possible.}, the participant performs some cognitive operations leading to identify sufficient information to describe a context.

So the quoted text in a reply message is assumed to be sufficient. 

FIXME develop the idea

The objective is so to determine which parts of the reply messages are reused from the source message.

As declared in the RFC~3676\footnote{\url{http://www.ietf.org/rfc/rfc3676.txt}}, we consider the lines of a message to be quoted if the first character is the quote mark "\texttt{>}".

Unfortunately the process of replying a message lead to some transformations to the original messages. Among them some error of character encoding decoding problem, lines splitting... 

While the form could be acceptable for some basic experiment, we decide to deploy an alignment procedure for various reasons: get the original form of the text which is quoted. 
Accessing the original message layout for new features. 
To go further, the original context of the extracted text in the source message also conveys some information.
For instance, a sentence from the source message, not present in the reply message but following an aligned sentence can be considered as starting a segment.

In the present paper, we have just used the correct form of the 

This is importance since the segmenter is intended to work on non noisy data (new content in message).

The underling idea is to use intrinsic characteristics of the quoted sentences as features for building the future segmentation models. As a consequence noisy data may lead to produce less sure features.


The meaning we give to the term of sentence is more linguistically-based. FIXME



We will assume the greater-than sign to be universal. 




We assume there is no deletion of original text between two consecutive quoted part.

TODO 
\begin{enumerate}
\item 
\item FIXME provide an example of generation and resulting annotation and 
\end{enumerate}

FIXME When a message is replied to in e-mail, Internet forums, or Usenet, the original can often be included, or "quoted", in a variety of different posting styles.
%
The main options are {\em interleaved posting} (also called {\em inline replying}, in which the different parts of the reply follow the relevant parts of the original post), \textit{bottom-posting} (in which the reply follows the quote) or \textit{top-posting} (in which the reply precedes the quoted original message). 


%------------------------------------------------------------------------------
\subsubsection{Annotation scheme}
\label{}


We assume that a message can be split into %subsequent and
 consecutive discourse segments, each of them conveying its own dialogue act.
We assume the sentence as the elementary unit.
Consequently, each sentence in a segment can play one of the following roles: 
\begin{description}
\item [starting and ending] (\textit{SE}) a segment when there is only one sentence in the segment, 
\item [starting] (\textit{S}) a segment if there are at least two sentences in the segment and the sentence is the first one, 
\item [ending] (\textit{E}) a segment if there are at least two sentences in the segment and the sentence is the last one, 
\item [inside] (\textit{I}) a segment in any other cases.
\end{description}
%
As a matter of fact, this scheme is similar to the \textit{BIO} annotation scheme except it is at the sentence level and not at the token level.
% [STARTEND] if the sentence of the source message is surrounded by insertions which are part of the reply message;
%[START] else if the sentence of the source message is surrounded by insertions which are part of the reply message;
%Par exemple, on pourra étiqueter de \texttt{TERMINE} la phrase précédent un segment repris et de \texttt{DEBUTE} la première phrase du segment repris. Ces phrases ainsi annotées dans leur contexte constitueront notre corpus d'entraînement.


We choose to work on the sentences p



%------------------------------------------------------------------------------
\subsubsection{Generation procedure}
\label{}

In the following procedure, the tokens are used to index the quoted lines and the sentences. 




\begin{enumerate}
\item List the source and the reply messages
\item For each pair of source and reply messages
\begin{enumerate}
\item Tokenize both messages in words and sentences
\item Identify % the tokens which are part of 
the quoted lines in the reply message
\item Identify the sentences which are part of the quoted text in the reply message
\item Align the sentences from the source message with the ones from the quoted text in the reply message 
\item For each identified quoted sentences 
\begin{enumerate}
\item Assign a role in terms of segmentation instructions
\end{enumerate}
\end{enumerate}
\end{enumerate}

The identification of a reply message is based on the \texttt{in-reply-to} meta data present in the email headers.



%------------------------------------------------------------------------------
\subsubsection{Alignment module}
\label{}



For finding alignments between two given text messages, we use 
%an implementation of the % Implements a portion of the
% NIST align/scoring 
%algorithm to compare a reference string to a hypothesis string. 
a \textit{dynamic programming (DP) string alignment algorithm} \cite{sankoff:1983}. 
In the context of speech recognition, the algorithm is also known as the \textit{NIST align/scoring algorithm}. Indeed, it is widely used to evaluate the output of speech recognition systems by comparing the hypothesized text (HYP) output by the speech recognizer to the correct, or reference (REF) text. 
In particular, it is used to compute the word error rate (WER) and the sentence error rate (SER).

The ``DP string alignment algorithm performs a global minimization of a Levenshtein distance function which weights the cost of correct words, insertions, deletions and substitutions as 0, 75, 75 and 100 respectively.
%
The computational complexity of DP is $0(NN)$.''
%    final static int MAX_PENALTY = 1000000;
%    final static int SUBSTITUTION_PENALTY = 100;
%    final static int INSERTION_PENALTY = 75;
%    final static int DELETION_PENALTY = 75;
%The alignment and metrics are intended to be, by default, identical to those of the \url{http://www.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm} NIST SCLITE tool.  
%The program sclite is a tool for scoring and evaluating the output of speech recognition systems. Sclite is part of the NIST SCTK Scoring Tookit. The program compares the hypothesized text (HYP) output by the speech recognizer to the correct, or reference (REF) text. After comparing REF to HYP, (a process called alignment), statistics are gathered during the scoring process and a variety of reports can be produced to summarize the performance of the recognition system.
%\url{http://www1.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm}



%CMU Sphinx
%Open Source Toolkit For Speech Recognition
%Project by Carnegie Mellon University
% of the performance of a speech recognition or machine translation system.



The Carnegie Mellon University provides an implementation of the algorithm in its speech recognition toolkit\footnote{Sphinx 4 \texttt{edu.cmu.sphinx.util.NISTAlign} %source code.
\url{http://cmusphinx.sourceforge.net}}.
%Implements a portion of the NIST align/scoring algorithm to compare a reference string to a hypothesis string.  It only keeps track of substitutions, insertions, and deletions.
We use an adaptation of it which allows to work on lists of strings\footnote{\url{https://github.com/romanows/WordSequenceAligner}} and not directly on strings (as sequences of characters).


%and other statistics available from an alignment of a hypothesis string and a reference string.

In comparison to the speech recognition and translation use cases, despite some noise, the compared text should include identical parts of the source one.





% -----------------------------------------------------------------------------
\subsection{Building the segmenter}


Our email speech act segmenter system is built around a linear-chain Conditional Random Field (CRF) classifier, as implemented in the sequence labelling toolkit Wapiti \cite{lavergne2010practical}. Each email is processed as a sequence and each sentence as an element of that sequence.

\subsubsection{Features for boundary detection}

The classifier uses features that capture graphic, orthographic, lexical and syntactic information about the sentence. Many of them are borrowed from related work in speech act classification \cite{qadir2011classifying} and email segmentation \cite{lampert2009segmenting}.

\subsubsection{Lexical and syntactic features}

\textbf{Ngrams:} we focus on the first and last three significant tokens in the sentence. Significance is determined by the number of occurrences of the token in the training corpus: terms with a frequency lower than \todo{fix me} 1/X are considered insignificant. 

If a sentence contains less than six significant tokens, the same token can be found in both triplets. For example, in the sentence \textit{``Have a good day !''}, the first three tokens would be \textit{``Have''}, \textit{``a''}, \textit{``good''} and the last three would be \textit{``good''}, \textit{``day''} and \textit{``!''}. If the sentence contains less than three significant tokens, missing values are replaced by a placeholder.

We define three individual features for the three unigrams, the two bigrams and the single trigram found in each of these sets. The features are the following: the unaltered form of the token (case-sensitive), the lemmatized form of the token (case-insensitive ; numbers present in the token are replaced by a special character) and the corresponding part-of-speech.

We use the Stanford Log-linear Part-Of-Speech Tagger for morpho-syntactic tagging \cite{toutanova2003feature}, and the WordNet lexical database to perform lemmatization \cite{miller1995wordnet}.

\textbf{Question words and interrogative ngrams:} one feature checks if a sentence begins with a ``wh*'' question word  (\textit{``who''}, \textit{``when''}, \textit{``where''}, \textit{``what''}, \textit{``which''}, \textit{``what''}, \textit{``how''}) or an ngram suggesting an incoming interrogation (e.g. \textit{``is it''} or \textit{``are there''}), and another one checks if the sentence merely contains such a word or ngram.

\textbf{Modals:} one feature indicates wether the sentence contains a modal (\textit{``may''}, \textit{``must''}, \textit{``shall''}, \textit{``will''}, \textit{``might''}, \textit{``should''}, \textit{``would''}, \textit{``could''}, and their negative forms).

\textbf{Plan phrases:} one feature looks for plan phrases (e.g. \textit{``i will''} or \textit{``we are going to''})

\textbf{Personal words:} three features check for first person, second person and third persons words, respectively (e.g. \textit{``we''}, \textit{``my''} and \textit{``me''} are recognized as first person words).

\textbf{First personal pronoun:} one feature records the first personal pronoun found in the sentence.

\textbf{First verbal form:} one feature records the tag of the first verbal form found in the sentence as classified by the Stanford Part-Of-Speech tagger ; that is an element of the Penn Treebank tag set \footnote{Alphabetical list of part-of-speech tags used in the Penn Treebank Project: \url{http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html}} (e.g. the feature \textit{``VBZ''} indicates a present tense verb in third person singular).

\subsubsection{Graphic features}

The following features' values are relative to other sentences. Four classes are defined for each feature: ``highest'' (top 25\%), ``high'' (top 50\%), ``low'' (bottom 50\%) and ``lowest'' (bottom 25\%).\newline

\textbf{Number of tokens:} the total number of tokens in the sentence, including insignificant ones.

\textbf{Number of characters:} the total number of characters in the sentence, including those in insignificant tokens.

\textbf{Average token length:} the average length of a token, including insignificant ones.

\textbf{Proportion of uppercase characters:} the proportion of uppercase characters in the sentence.

\textbf{Proportion of alphabetic characters:} the proportion of alphabetic characters in the sentence.

\textbf{Proportion of numeric characters:} the proportion of numeric characters in the sentence.

\subsubsection{Orthographic features}

\textbf{Number of greater-than signs:} the number of greater-than signs (``>''), also know as ``chevron'' symbols, in the sentence. Like previous features, this one is computed relatively to other sentences in the training set.

\textbf{Position:} the position of the sentence in the email.

\textbf{Question mark:} one feature checks if the sentence ends with a question mark, and another checks if it at least contains one.

\textbf{Colon:} one feature checks if the sentence ends with a colon, and another checks if it at least contains one.

\textbf{Semicolon:} one feature checks if the sentence ends with a semicolon, and another checks if it at least contains one.

\textbf{Early punctuation:} the last feature checks if the sentence contains any punctuation within the first three tokens of the sentence. This is meant to recognize greetings \cite{qadir2011classifying}.

