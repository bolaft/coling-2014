
%------------------------------------------------------------------------------
\section{Approach}
\label{}

\textbf{TODO}
\begin{enumerate}
\item un exemple de segmentation que l'on souhaite
\item 
\end{enumerate}


Figure~\ref{fig:exampleSourCeReplyMessage} shows an example of a source message\footnote{In the original message, $S3$ and $S4$ consist in one single sentence with a comma as a separator. We split it into distinct sentences in order to illustrate the \textit{Inside} label.} (Figure~\ref{fig:exampleSource}) and one of its reply (Figure~\ref{fig:exampleReply}).
Pseudo-sentences have been marked to make easier the explanations. 
They also correspond to what an automatic process can produce.
In this example, we can see that the reply message only re-uses four selected sentences from the source message; Namely $S2$, $S3$, $S4$ and $S5$ which respectively correspond to the sentences  $R2$, $R3$, $R4$ and $R9$ in the reply messages.
The author of the reply message deliberately discarded the remaining of the source message.

\begin{figure}
%\begin{multicols}{2}[]

%\begin{multicols}{1}[]
    %    \centering
\fbox {
    \parbox{\linewidth}{
        \begin{subfigure}[b]{0.9\textwidth}
\small
%\footnotesize
[Hi ubuntu-ers,]$^{S1}$\vspace{0.1cm}

[I'm in need of some directions.]$^{S2}$ [I want to run ubuntu for my desktop.]$^{S3}$\\ \ 
[But the installer doesn't support root or boot on raid.]$^{S4}$  \vspace{0.1cm}
%[I'm in need of some directions.]$^{S2}$ [I want to run ubuntu for my desktop,\\
%but the installer doesn't support root or boot on raid.]$^{S3}$  \vspace{0.1cm}

[It seems that there must be a way to convert to raid after the fact, as \\
I've seen for some other distros.]$^{S5}$\vspace{0.1cm}

[I've tried a couple of the other distro specific directions, and just %\
wind up with a kernel panic.]$^{S6}$  \vspace{0.1cm}

[Are there some ubuntu specific instructions or advice?]$^{S7}$  [Thanks.]$^{S8}$\vspace{0.1cm}

%-- \\ \ 
%[Regards,]$^{S8}$ \\ \ 
[John]$^{S9}$
%Rich
              %  \includegraphics[width=\textwidth]{gull}

                \caption{Source message.}
                \label{fig:exampleSource}
        \end{subfigure}%
}}
\vspace{0.2cm}
\\
       % ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
\fbox {
    \parbox{\linewidth}{
        \begin{subfigure}[b]{0.9\textwidth}
\small
%\footnotesize
%[On Sun, 04 Dec 2005 15:45:13 -0600, John Doe\\
[On Sun, 04 Dec 2005 15:45:13 -0600, John Doe 
%On Sun, 05 Dec 2004 16:48:14 -0600, Rich Duzenbury
%<rduz-ubuntu@theduz.com> wrote:
<john@doe.com> wrote:]$^{R1}$\vspace{0.1cm}

%> [I'm in need of some directions.]$^{R2}$  [I want to run ubuntu for my desktop,\\
%> but the installer doesn't support root or boot on raid.]$^{R3}$\vspace{0.1cm}
> [I'm in need of some directions.]$^{R2}$  [I want to run ubuntu for my desktop.]$^{R3}$\\
> [But the installer doesn't support root or boot on raid.]$^{R4}$\vspace{0.1cm}

[It claims not to.]$^{R5}$ [It actually does work.]$^{R6}$\vspace{0.1cm}

[Create a separate /boot partition for the kernel and initrd to live in %\\
and then install to a / filesystem living on a RAID1 or RAID0 device %\\
that you create during the install.]$^{R7}$ [My ubuntu server in the office %\\
currently has 4 active disks doing RAID0+1 and running LVM on top with % \\
another disk about to go in in case 2 happen to fail in quick % \\
succession :-)]$^{R8}$\vspace{0.1cm}

> [It seems that there must be a way to convert to raid after the fact, as\\
> I've seen for some other distros.]$^{R9}$\vspace{0.1cm}

[It's also possible to convert after the fact using generic %\\
instructions and rebuilding the initrd to cope with the fact that it % \\
will need to run mdadm for you.]$^{R10}$\vspace{0.1cm}

%[Cheers,]$^{R10}$\vspace{0.1cm}

[Bob.]$^{R11}$ %\vspace{0.1cm}
%Jon.

%[P.S.]$^{R11}$ [This is a major sticking point for ubuntu and Debian acceptance\\
%on mission critical kit which should be addressed.]$^{R12}$ [It's not too tricky\\
%to boot and initrd off a separate boot partition.]$^{R13}$\vspace{0.1cm}

               % \includegraphics[width=\textwidth]{tiger}
                \caption{Reply message.}
                \label{fig:exampleReply}
        \end{subfigure}
}}
%\end{multicols}

%        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
%          %(or a blank line to force the subfigure onto a new line)
%        \begin{subfigure}[b]{0.4\textwidth}


%\begin{tabular}{*{2}{|l}|c|}
%\toprule
%\textbf{Source} & \textbf{Reply} & \textbf{Label}\\
%	\midrule
%S1  & & \\
%    & R1 & \\
%\textit{S2}  & > \textit{R2}& Start\\
%\textit{S3}  & > \textit{R3}& Inside\\
%\textit{S4}  & > \textit{R4}& End\\
%    & R5 & \\
%    & R6 & \\
%    & R7 & \\
%\textit{S5}  & > \textit{R8} & Start \& End\\
%    & R9 & \\
%%    & R10 & \\
%    & [...] & \\
%S7    &  & \\ \ 
%[...] \    &  & \\
%	\bottomrule
%\end{tabular}
%               % \includegraphics[width=\textwidth]{mouse}
%                \caption{A mouse}
%                \label{fig:mouse}
%        \end{subfigure}
        \caption{Example of a source message and its reply. Pseudo-sentences have been marked to make easier the explanations. The original layout has been slightly adapted to fit the document.}\label{fig:exampleSourCeReplyMessage}
%\end{multicols}

\end{figure}




\begin{figure}\small\centering
\begin{tabular}{*{2}{|l}|c|}
\toprule
\textbf{Source} & \textbf{Reply} & \textbf{Label}\\
	\midrule
S1  & & \\
    & R1 & \\
\textit{S2}  & > \textit{R2}& \texttt{Start}\\
\textit{S3}  & > \textit{R3}& \texttt{Inside}\\
\textit{S4}  & > \textit{R4}& \texttt{End}\\
    & R5 & \\
    & R6 & \\
    & R7 & \\
    & R8 & \\
\textit{S5}  & > \textit{R9} & \texttt{Start\&End}\\
    & R10 & \\
%    & R11 & \\
    & [...] & \\
S7    &  & \\ \ 
[...] \    &  & \\
	\bottomrule
\end{tabular}

\caption{Sentences alignment of the source and the reply messages from the Figure~\ref{fig:exampleSourCeReplyMessage}. Examples of segmentation labels which can be inferred from the text re-use of the source message and associated to the source sentences.}
\label{fig:exampleSegmentationLabels}
\end{figure}


%------------------------------------------------------------------------------
\subsection{Building annotated corpora of segmented online discussions at no cost}
\label{}

The basic idea is to interpret the operation performed by a discussion participant on the message he replies as an annotation operation. 
Assumptions about the kind of annotations depend on the kind of the performed operation.
Deletion or re-use of the source text material can give hints about the relevance of the content. Discarded material is probably less relevant than re-used one.

We assume that by replying inside a message and by only including some specific parts, the participant performs some cognitive operations to identify homogeneous self-contained text segments in the original message.
We assume that the quoted part consists in an homogeneous information unit with respect to the context from which it is extracted. 
Consequently, we make assumptions about the role played by the sentences in the structure of the information in the original message.
For instance, we could assume that the first sentence of a quoted part conveys instructions for opening a new discourse segment while the last sentence carries instructions for ending a segment.

%in terms of relevance or role in the discourse organisation can be expressed on the new content, on the quoted text or even on the text which is not reused in the reply message.

%In this paper, we choose to assume that the sentences of the quoted text in a reply message can inform

%The original message consists in an homogeneous discourse flow of utterances. 

%By replying to a message and by extracting deliberately some parts\footnote{Summarization operations are also possible.}, the participant performs some cognitive operations leading to identify sufficient information to describe a context.

% So the quoted text in a reply message is assumed to be sufficient. 

% FIXME develop the idea

% The objective is so to determine which parts of the reply messages are reused from the source message.

Before inferring some labels to some sentences of the original message, the task is to identify the sentences which are re-used in a reply message. 
Identification of the quoted lines in a reply message is not sufficient for various reasons. 
%
First, the segmenter is intended to work on non noisy data (i.e. the new content in messages). 
The quoted text suffers from multiple transformations (See section FIXME).  
So, building a model on an altered version of the original message would create a bias in the approach.
Second, accessing the original message may allow to consider in the model some contextual features (like the visual layout). 
Third, to go further, the original context of the extracted text in the source message also conveys some segmentation information. For instance, a sentence from the source message, not present in the reply message but following an aligned sentence can be considered as starting a segment.
So in addition of identifying the quoted lines, we deploy an alignment procedure to get the original version of the quoted text. 
In this paper, we did not consider the contextual features from the original message and focus only on original aligned sentences. 

%While the form could be acceptable for some basic experiment, we decide to deploy an alignment procedure for various reasons: get the original form of the text which is quoted. 




%------------------------------------------------------------------------------
\subsubsection{A quoted message is an altered version of the original one}
\label{}


The process of exchanging messages involves distinct software agents to transfer and deliver the messages to an user. % between the hosts. The 
When received, the email are stored by dedicated servers until they retrieved by the user.
%
The program used by users for retrieving and managing emails is called a mail user agent (MUA). 
The MUA reads and formats the message in email format to send it.

New content sent by a writer is in general read by the reader in its expected visual rendering. 
But this cannot be the case of previous message content for various reasons.



The email %header and body 
formats and encodings are specified by several RFC\footnote{The \textit{Request for Comments} are guidelines and protocols which result from various working groups involved in the Internet Standardization \url{https://tools.ietf.org/html}.}
%
The RFC 822 proposed in August 1982 specifies a Standard for the Format of ARPA Internet Text Messages which is the ancestor of the current message format. This RFC was obsoleted by the RFC 2822  proposed in April 2001 which defines the original Internet Message Format. This RFC was updated in October 2008 by the RFC 5322 and in turn obsoleted in March 2013 by the RFC 6854.
%
The format of the Internet message bodies has been sub-specified by several recommendations and updates; See as a main entrance the RFC 2045 from November 1996 or its more recent update, the RFC 5335 from September 2008. These specifications are called the Multipurpose Internet Mail Extensions (MIME).


% email header and body
% https://tools.ietf.org/html/rfc2822  April 2001
% http://tools.ietf.org/html/rfc5322 October 2008
% http://tools.ietf.org/html/rfc6854 March 2013
% Multipurpose Internet Mail Extensions   Format of Internet Message Bodies
% http://tools.ietf.org/html/rfc2045 November 1996
% https://tools.ietf.org/html/rfc5335 September 2008

As a matter of facts, messages in a discussion are handled by several distinct email software clients which are not always standards-compliant and totally compatible.
So each of them can integrate their own mechanisms 
for quoting the previous messages when including them as well as 
for wrapping the too long lines\footnote{Feature for limiting the line length by splitting them into multiple pieces of no more than 80 characters and make the text readable without any horizontal scrolling.}.
%
In addition, because of some user preferences or systems configurations, a thread may embed and interleave various posting styles.  

As a consequences a discussion is a mix of various transformation mechanisms which can be equated to a noisy canal. 
%
One of the transformation issue concerns the encoding and the decoding of the quoted parts which can be wrongly recoded at each exchange step.

% Previous messages are not included as a verbatim copy of the original one.

% of 65-80 characters, 
% In text display, line wrap is the feature of continuing on a new line when a line is full, such that each line fits in the viewable window, allowing text to be read from top to bottom without any horizontal scrolling. 
%http://en.wikipedia.org/wiki/Word_wrap

% Programs used by users for retrieving, reading, and managing email are called mail user agents (MUAs).

% The process of replying to a message by including the original message does not ensure to provide a pure duplicate of the original. 







%------------------------------------------------------------------------------
\subsubsection{Annotation scheme}
\label{}


We assume that a message can be split into %subsequent and
 consecutive discourse segments, each of them conveying its own dialogue act.
We assume the sentence as the elementary unit.
Consequently, each sentence in a segment can play one of the following roles: 
\begin{description}
\item [starting and ending] (\textit{SE}) a segment when there is only one sentence in the segment, 
\item [starting] (\textit{S}) a segment if there are at least two sentences in the segment and the sentence is the first one, 
\item [ending] (\textit{E}) a segment if there are at least two sentences in the segment and the sentence is the last one, 
\item [inside] (\textit{I}) a segment in any other cases.
\end{description}
%
As a matter of fact, this scheme is similar to the \textit{BIO} annotation scheme except it is at the sentence level and not at the token level.
% [STARTEND] if the sentence of the source message is surrounded by insertions which are part of the reply message;
%[START] else if the sentence of the source message is surrounded by insertions which are part of the reply message;
%Par exemple, on pourra étiqueter de \texttt{TERMINE} la phrase précédent un segment repris et de \texttt{DEBUTE} la première phrase du segment repris. Ces phrases ainsi annotées dans leur contexte constitueront notre corpus d'entraînement.






%------------------------------------------------------------------------------
\subsubsection{Annotation generation procedure}
\label{}

The generation process aims at "automatically" annotating sentences from the source messages with segmentation information.
Figure~\ref{fig:procedureTrainingDataGeneration} describes the steps of the generation procedure at the global level. 
Each message from our corpus are tokenized and the sentences split. 
The quoted lines in the reply messages are identified based on the presence of a specific prefix at the beginning of the lines. 
As declared in the RFC~3676\footnote{\url{http://www.ietf.org/rfc/rfc3676.txt}}, we consider the lines of a message to be quoted if the first character is the mark "\texttt{>}" (greater than).
%
Pair of source and reply messages are made up based on the \texttt{in-reply-to} field present in the email headers.
The word tokens are used to index the quoted lines and the sentences. 
Section~\ref{secalignmentmodule} describes our method to align the quoted sentences from the reply messages with the sentences from the source messages. 
Figure~\ref{fig:algoLabellingEachAlignedSentence} gives some precisions about the algorithm for labelling each aligned sentence with a segmentation instruction. 


FIXME The meaning we give to the term of sentence is more linguistically-based. 

FIXME We assume there is no deletion of original text between two consecutive quoted part.

\begin{figure}[ht!]
%\begin{enumerate}
%\item List the source and the reply messages
%\item 
\fbox {
    \parbox{\linewidth}{
For each pair of source and reply messages
\begin{enumerate}
\item Tokenize both messages in words and sentences
\item Identify % the tokens which are part of 
the quoted lines in the reply message
\item Identify the sentences which are part of the quoted text in the reply message
\item Align the sentences from the source message with the ones from the quoted text in the reply message 
%\item For each aligned sentence 
%\begin{enumerate}
\item Label each aligned source sentence in terms of its segmentation role (See~Figure~\ref{fig:algoLabellingEachAlignedSentence})
%\end{enumerate}
\item Add to the training data the labelled message made up by the sequence of labelled sentences %The sequence of labelled sentences makes up a labelled message which is add to the training data 
\end{enumerate}
}}

%\end{enumerate}
\caption{Procedure for generating the training data}
\label{fig:procedureTrainingDataGeneration}
\end{figure}


\begin{figure}[ht!]
%\fbox{
%\begin{enumerate}
%\item 
\fbox {
    \parbox{\linewidth}{
For each aligned source sentence %identified quoted sentence
 (sentence from the source message re-used in the reply message)
\begin{itemize}
\item if the sentence is surrounded by new content in the reply message, then label it \texttt{Start\&End}
%both the previous and the next sentences are part of the
\begin{itemize}
\item[$\bullet$] else if the sentence is preceded by a new content, then label it  \texttt{Start}
\begin{itemize}
\item[$\bullet$] else if the sentence is followed by a new content, then label it  \texttt{End}
\begin{itemize}
\item[$\bullet$] else label it  \texttt{Inside}
\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}
    }
}

%}
%\end{enumerate}
\caption{Algorithm for labelling each aligned sentence with a segmentation instruction}
\label{fig:algoLabellingEachAlignedSentence}
\end{figure}




%------------------------------------------------------------------------------
\subsubsection{Alignment module}
\label{secalignmentmodule}



For finding alignments between two given text messages, we use 
%an implementation of the % Implements a portion of the
% NIST align/scoring 
%algorithm to compare a reference string to a hypothesis string. 
a \textit{dynamic programming (DP) string alignment algorithm} \cite{sankoff:1983}. 
In the context of speech recognition, the algorithm is also known as the \textit{NIST align/scoring algorithm}. Indeed, it is widely used to evaluate the output of speech recognition systems by comparing the hypothesized text %(HYP) 
output by the speech recognizer to the correct, or reference % (REF) 
text. 
%In particular, it is used to compute the word error rate (WER) and the sentence error rate (SER).
%
The %``DP string alignment 
algorithm works by ``performing a global minimization of a Levenshtein distance function which weights the cost of correct words, insertions, deletions and substitutions as 0, 75, 75 and 100 respectively.
%
The computational complexity of DP is $0(NN)$.''
%    final static int MAX_PENALTY = 1000000;
%    final static int SUBSTITUTION_PENALTY = 100;
%    final static int INSERTION_PENALTY = 75;
%    final static int DELETION_PENALTY = 75;
%The alignment and metrics are intended to be, by default, identical to those of the \url{http://www.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm} NIST SCLITE tool.  
%The program sclite is a tool for scoring and evaluating the output of speech recognition systems. Sclite is part of the NIST SCTK Scoring Tookit. The program compares the hypothesized text (HYP) output by the speech recognizer to the correct, or reference (REF) text. After comparing REF to HYP, (a process called alignment), statistics are gathered during the scoring process and a variety of reports can be produced to summarize the performance of the recognition system.
%\url{http://www1.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm}



%CMU Sphinx
%Open Source Toolkit For Speech Recognition
%Project by Carnegie Mellon University
% of the performance of a speech recognition or machine translation system.



The Carnegie Mellon University provides an implementation of the algorithm in its speech recognition toolkit\footnote{Sphinx 4 \texttt{edu.cmu.sphinx.util.NISTAlign} %source code.
\url{http://cmusphinx.sourceforge.net}}.
%Implements a portion of the NIST align/scoring algorithm to compare a reference string to a hypothesis string.  It only keeps track of substitutions, insertions, and deletions.
We use an adaptation of it which allows to work on lists of strings\footnote{\url{https://github.com/romanows/WordSequenceAligner}} and not directly on strings (as sequences of characters).


%and other statistics available from an alignment of a hypothesis string and a reference string.

In comparison to the speech recognition and translation use cases, despite some noise, the compared text should include identical parts of the source one.



%------------------------------------------------------------------------------
\subsubsection{Restrictions}
\label{}

Focus on the first message of a thread and its reply messages to avoid noisy data due to several levels of quoted lines.

Restrict on short messages as an heuristic to filter out the long code trace message

Due to alignment complexity focus only on the first 25 000 tokens.

In source message, focus on part which is new ; in reply message, focus on part which is new + only the first? quoted level 
 


% -----------------------------------------------------------------------------
\subsection{Building the segmenter}

Our email segmenter is built around a linear-chain Conditional Random Field (CRF) classifier, as implemented in the sequence labelling toolkit Wapiti \cite{lavergne2010practical}. Each email is processed as a sequence and each sentence as an element of that sequence.

The classifier uses features that capture syntactic, stylistic and lexical information about the sentence. Several of them are borrowed from related work in speech act classification \cite{qadir2011classifying} and email segmentation \cite{lampert2009segmenting}. All the features are domain-independant. Almost all features are language-independant as well, save for a few that can be easily translated.

For the purposes of analysis and experimentation, the feature set is separated into four groups: syntactic features, lexical features, stylistic features and thematic features.

\subsubsection{Syntactic features}

We focus on the first and last three significant tokens in the sentence, which often serve as connectors to adjoining sentences and therefore hold important structural information.

Token significance is determined by the number of occurrences of the token in the training corpus: terms with a frequency lower than 1/2000 are considered insignificant. If a sentence contains less than six significant tokens, the same token can be found in both triplets. If the sentence contains less than three significant tokens, missing values are replaced by a placeholder.

We define three individual features for each of the three unigrams, the two bigrams and the single trigram found in each of these triplets. The features are the following: the unaltered form of each token (case-sensitive), their lemmatized form (case-insensitive) and their corresponding part-of-speech. This is illustrated in figure ~\ref{fig:exampleSyntacticFeatures}.

We use the Stanford Log-linear Part-Of-Speech Tagger for morpho-syntactic tagging \cite{toutanova2003feature}, and the WordNet lexical database to perform lemmatization \cite{miller1995wordnet}.

\begin{figure}\small\centering
\begin{tabular}{*{2}{|l}|l|}
\toprule
\textbf{Surface form} & \textbf{Lemma} & \textbf{P.O.S.}\\
	\midrule
	Many & many & JJ\\
	thanks & thanks & NNS\\
	to & to & TO\\
	your & your & PRP\\
	suggestions & suggestion & DD\\
	. & . & .\\
	Many thanks & many thanks & JJ NNS\\
	thanks to . & thanks to . & NNS TO . \\
	your suggestions & your suggestion & PRP DD\\
	suggestions & suggestion & DD\\
	Many thanks to & many thanks to & JJ NNS TO\\
	your suggestions . & your suggestion . & PRP DD .\\
	\bottomrule
\end{tabular}

\caption{Syntactic features formed from the sentence "\textit{Many thanks to all of you for the help you have offered, I have learned tremendously from all your suggestions.}" Each cell is a feature.}
\label{fig:exampleSyntacticFeatures}
\end{figure}

\subsubsection{Lexical features}

We select the 1000 bigrams and trigrams with the highest document frequency in the training data, and check for their presence in each sentence. Since the probability of having multiple occurrences of the same n-gram in one sentence are extremely low, we do not record the number of occurrences but merely a boolean value. The check is case-insensitive.

\subsubsection{Stylistic features}

Stylistic features include graphic, orthographic and semantic features. \textbf{Graphic features} capture information about the visual structure and composition of the message:

\begin{itemize}
	\item the position of the sentence in the email
	\item the average length of a token
	\item the total number of tokens
	\item the total number of characters
	\item the proportion of uppercase, alphabetic and numeric characters
\end{itemize}

\textbf{Orthographic features} capture information about the use of distinctive characters or character sequences:

\begin{itemize}
	\item the number of greater-than signs (``>''), also know as ``chevron'' symbols, in the sentence
	\item whether the sentence ends with a question mark, a colon or a semicolon, or if it at least contains one (three features)
	\item whether the sentence contains any punctuation within the first three tokens (this is meant to recognize greetings \cite{qadir2011classifying})
\end{itemize}

\textbf{Semantic features} check for meaningful words and phrases:

\begin{itemize}
	\item whether the sentence begins with a ``wh*'' question word  (\textit{``who''}, \textit{``when''}, \textit{``where''}, \textit{``what''}, \textit{``which''}, \textit{``what''}, \textit{``how''}) or an n-gram suggesting an incoming interrogation (e.g. \textit{``is it''} or \textit{``are there''}), and whether the sentence merely contains such a word or n-gram
	\item whether the sentence contains a modal (\textit{``may''}, \textit{``must''}, \textit{``shall''}, \textit{``will''}, \textit{``might''}, \textit{``should''}, \textit{``would''}, \textit{``could''}, and their negative forms)
	\item whether any plan phrases (e.g. \textit{``i will''} or \textit{``we are going to''}) are present
	\item whether the sentence contains first person, second person or third persons words (e.g. \textit{``we''}, \textit{``my''} and \textit{``me''} are recognized as first person words)
	\item the first personal pronoun found in the sentence
	\item the first verbal form found in the sentence as classified by the Stanford Part-Of-Speech tagger ; that is an element of the Penn Treebank tag set \footnote{Alphabetical list of part-of-speech tags used in the Penn Treebank Project: \url{http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html}} (e.g. the feature \textit{``VBZ''} indicates a present tense verb in third person singular)
\end{itemize}

\subsubsection{Thematic features}

The only feature we use to account for thematic shift recognition is the output of the Text Tiling algorithm \cite{hearst1997texttiling}. Text Tiling is one of the most commonly used algorithms for automatic text segmentation. It is a statistical method for thematic segmentation, i.e. a method that attempts to segment texts according to the contrasting themes of its parts: if the algorithm detects a rupture in the thematic continuity of the text, it will place a boundary to indicate a thematic change. This method is based on the notion of lexical cohesion.

\subsubsection{Labels}

Training the classifier to recognize the different labels of the previously defined annotation scheme can be problematic. It has indeed some disadvantages that can undermine the effectiveness of the classifier. In particular, sentences annotated \textit{SE} will, by definition, share important characteristics with sentences bearing the annotation \textit{S} and \textit{E}. For the purposes of segmentation, we chose to transform these annotations into a binary scheme and merely differentiate sentences that start a new segment (\textit{True}), or "boundary sentences", from those that do not (\textit{False}). The conversion process is trivial, and can easily be reversed:

\begin{itemize}
    \item \textit{SE} $\longrightarrow$ \textit{True} $\longrightarrow$ \textit{SE} (if the next sentence is also a boundary)
    \item \textit{S} $\longrightarrow$ \textit{True} $\longrightarrow$ \textit{S} (if the next sentence is not a boundary)
    \item \textit{I} $\longrightarrow$ \textit{False} $\longrightarrow$ \textit{I} (if the next sentence is not a boundary either)
    \item \textit{E} $\longrightarrow$ \textit{False} $\longrightarrow$ \textit{E} (if the next sentence is a boundary)
\end{itemize}
