
%------------------------------------------------------------------------------
\section{Approach}
\label{}

\textbf{TODO}
\begin{enumerate}
\item 
\item 
\end{enumerate}


Figure~\ref{fig:exampleSourCeReplyMessage} shows an example of a source message\footnote{In the original message, $S3$ and $S4$ consist in one single sentence with a comma as a separator. We split it into distinct sentences in order to illustrate the \textit{Inside} label.} (Figure~\ref{fig:exampleSource}) and one of its reply (Figure~\ref{fig:exampleReply}).
Pseudo-sentences have been marked to make easier the explanations. 
They also correspond to what an automatic process can produce.
In this example, we can see that the reply message only re-uses four selected sentences from the source message; Namely $S2$, $S3$, $S4$ and $S5$ which respectively correspond to the sentences  $R2$, $R3$, $R4$ and $R9$ in the reply messages.
The author of the reply message deliberately discarded the remaining of the source message.

\begin{figure}
%\begin{multicols}{2}[]

%\begin{multicols}{1}[]
    %    \centering
\fbox {
    \parbox{\linewidth}{
        \begin{subfigure}[b]{0.9\textwidth}
\small
%\footnotesize
[Hi ubuntu-ers,]$^{S1}$\vspace{0.1cm}

[I'm in need of some directions.]$^{S2}$ [I want to run ubuntu for my desktop.]$^{S3}$\\ \ 
[But the installer doesn't support root or boot on raid.]$^{S4}$  \vspace{0.1cm}
%[I'm in need of some directions.]$^{S2}$ [I want to run ubuntu for my desktop,\\
%but the installer doesn't support root or boot on raid.]$^{S3}$  \vspace{0.1cm}

[It seems that there must be a way to convert to raid after the fact, as \\
I've seen for some other distros.]$^{S5}$\vspace{0.1cm}

[I've tried a couple of the other distro specific directions, and just %\
wind up with a kernel panic.]$^{S6}$  \vspace{0.1cm}

[Are there some ubuntu specific instructions or advice?]$^{S7}$  [Thanks.]$^{S8}$\vspace{0.1cm}

%-- \\ \ 
%[Regards,]$^{S8}$ \\ \ 
[John]$^{S9}$
%Rich
              %  \includegraphics[width=\textwidth]{gull}

                \caption{Source message.}
                \label{fig:exampleSource}
        \end{subfigure}%
}}
\vspace{0.2cm}
\\
       % ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
\fbox {
    \parbox{\linewidth}{
        \begin{subfigure}[b]{0.9\textwidth}
\small
%\footnotesize
%[On Sun, 04 Dec 2005 15:45:13 -0600, John Doe\\
[On Sun, 04 Dec 2005 15:45:13 -0600, John Doe 
%On Sun, 05 Dec 2004 16:48:14 -0600, Rich Duzenbury
%<rduz-ubuntu@theduz.com> wrote:
<john@doe.com> wrote:]$^{R1}$\vspace{0.1cm}

%> [I'm in need of some directions.]$^{R2}$  [I want to run ubuntu for my desktop,\\
%> but the installer doesn't support root or boot on raid.]$^{R3}$\vspace{0.1cm}
> [I'm in need of some directions.]$^{R2}$  [I want to run ubuntu for my desktop.]$^{R3}$\\
> [But the installer doesn't support root or boot on raid.]$^{R4}$\vspace{0.1cm}

[It claims not to.]$^{R5}$ [It actually does work.]$^{R6}$\vspace{0.1cm}

[Create a separate /boot partition for the kernel and initrd to live in %\\
and then install to a / filesystem living on a RAID1 or RAID0 device %\\
that you create during the install.]$^{R7}$ [My ubuntu server in the office %\\
currently has 4 active disks doing RAID0+1 and running LVM on top with % \\
another disk about to go in in case 2 happen to fail in quick % \\
succession :-)]$^{R8}$\vspace{0.1cm}

> [It seems that there must be a way to convert to raid after the fact, as\\
> I've seen for some other distros.]$^{R9}$\vspace{0.1cm}

[It's also possible to convert after the fact using generic %\\
instructions and rebuilding the initrd to cope with the fact that it % \\
will need to run mdadm for you.]$^{R10}$\vspace{0.1cm}

%[Cheers,]$^{R10}$\vspace{0.1cm}

[Bob.]$^{R11}$ %\vspace{0.1cm}
%Jon.

%[P.S.]$^{R11}$ [This is a major sticking point for ubuntu and Debian acceptance\\
%on mission critical kit which should be addressed.]$^{R12}$ [It's not too tricky\\
%to boot and initrd off a separate boot partition.]$^{R13}$\vspace{0.1cm}

               % \includegraphics[width=\textwidth]{tiger}
                \caption{Reply message.}
                \label{fig:exampleReply}
        \end{subfigure}
}}
%\end{multicols}

%        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
%          %(or a blank line to force the subfigure onto a new line)
%        \begin{subfigure}[b]{0.4\textwidth}


%\begin{tabular}{*{2}{|l}|c|}
%\toprule
%\textbf{Source} & \textbf{Reply} & \textbf{Label}\\
%	\midrule
%S1  & & \\
%    & R1 & \\
%\textit{S2}  & > \textit{R2}& Start\\
%\textit{S3}  & > \textit{R3}& Inside\\
%\textit{S4}  & > \textit{R4}& End\\
%    & R5 & \\
%    & R6 & \\
%    & R7 & \\
%\textit{S5}  & > \textit{R8} & Start \& End\\
%    & R9 & \\
%%    & R10 & \\
%    & [...] & \\
%S7    &  & \\ \ 
%[...] \    &  & \\
%	\bottomrule
%\end{tabular}
%               % \includegraphics[width=\textwidth]{mouse}
%                \caption{A mouse}
%                \label{fig:mouse}
%        \end{subfigure}
        \caption{Example of a source message and its reply. Pseudo-sentences have been marked to make easier the explanations. The original layout has been slightly adapted to fit the document.}\label{fig:exampleSourCeReplyMessage}
%\end{multicols}

\end{figure}




\begin{figure}\small\centering
\begin{tabular}{*{2}{|l}|c|}
\toprule
\textbf{Source} & \textbf{Reply} & \textbf{Label}\\
	\midrule
S1  & & \\
    & R1 & \\
\textit{S2}  & > \textit{R2}& \texttt{Start}\\
\textit{S3}  & > \textit{R3}& \texttt{Inside}\\
\textit{S4}  & > \textit{R4}& \texttt{End}\\
    & R5 & \\
    & R6 & \\
    & R7 & \\
    & R8 & \\
\textit{S5}  & > \textit{R9} & \texttt{Start\&End}\\
    & R10 & \\
%    & R11 & \\
    & [...] & \\
S7    &  & \\ \ 
[...] \    &  & \\
	\bottomrule
\end{tabular}

\caption{Sentences alignment of the source and the reply messages from the Figure~\ref{fig:exampleSourCeReplyMessage}. Examples of segmentation labels which can be inferred from the text re-use of the source message and associated to the source sentences.}
\label{fig:exampleSegmentationLabels}
\end{figure}


%------------------------------------------------------------------------------
\subsection{Building annotated corpora of segmented online discussions at no cost}
\label{}

The basic idea is to interpret the operation performed by a discussion participant on the message he replies as an annotation operation. 
Assumptions about the kind of annotations depend on the kind of the performed operation.
Deletion or re-use of the source text material can give hints about the relevance of the content. Discarded material is probably less relevant than re-used one.

We assume that by replying inside a message, the participant performs cognitive operations to identify text segments 

rhetorical segmentation. 

in terms of relevance or role in the discourse organisation can be expressed on the new content, on the quoted text or even on the text which is not reused in the reply message.

In this paper, we choose to assume that the sentences of the quoted text in a reply message can inform

The original message consists in an homogeneous discourse flow of utterances. 

By replying to a message and by extracting deliberately some parts\footnote{Summarization operations are also possible.}, the participant performs some cognitive operations leading to identify sufficient information to describe a context.

So the quoted text in a reply message is assumed to be sufficient. 

FIXME develop the idea

The objective is so to determine which parts of the reply messages are reused from the source message.

As declared in the RFC~3676\footnote{\url{http://www.ietf.org/rfc/rfc3676.txt}}, we consider the lines of a message to be quoted if the first character is the quote mark "\texttt{>}".

Unfortunately the process of replying a message lead to some transformations to the original messages. Among them some error of character encoding decoding problem, lines splitting... 

While the form could be acceptable for some basic experiment, we decide to deploy an alignment procedure for various reasons: get the original form of the text which is quoted. 
Accessing the original message layout for new features. 
To go further, the original context of the extracted text in the source message also conveys some information.
For instance, a sentence from the source message, not present in the reply message but following an aligned sentence can be considered as starting a segment.

In the present paper, we have just used the correct form of the 

This is importance since the segmenter is intended to work on non noisy data (new content in message).

The underling idea is to use intrinsic characteristics of the quoted sentences as features for building the future segmentation models. As a consequence noisy data may lead to produce less sure features.


The meaning we give to the term of sentence is more linguistically-based. FIXME



We will assume the greater-than sign to be universal. 




We assume there is no deletion of original text between two consecutive quoted part.



FIXME When a message is replied to in e-mail, Internet forums, or Usenet, the original can often be included, or "quoted", in a variety of different posting styles.
%
The main options are {\em interleaved posting} (also called {\em inline replying}, in which the different parts of the reply follow the relevant parts of the original post), \textit{bottom-posting} (in which the reply follows the quote) or \textit{top-posting} (in which the reply precedes the quoted original message). 


%------------------------------------------------------------------------------
\subsubsection{Annotation scheme}
\label{}


We assume that a message can be split into %subsequent and
 consecutive discourse segments, each of them conveying its own dialogue act.
We assume the sentence as the elementary unit.
Consequently, each sentence in a segment can play one of the following roles: 
\begin{description}
\item [starting and ending] (\textit{SE}) a segment when there is only one sentence in the segment, 
\item [starting] (\textit{S}) a segment if there are at least two sentences in the segment and the sentence is the first one, 
\item [ending] (\textit{E}) a segment if there are at least two sentences in the segment and the sentence is the last one, 
\item [inside] (\textit{I}) a segment in any other cases.
\end{description}
%
As a matter of fact, this scheme is similar to the \textit{BIO} annotation scheme except it is at the sentence level and not at the token level.
% [STARTEND] if the sentence of the source message is surrounded by insertions which are part of the reply message;
%[START] else if the sentence of the source message is surrounded by insertions which are part of the reply message;
%Par exemple, on pourra étiqueter de \texttt{TERMINE} la phrase précédent un segment repris et de \texttt{DEBUTE} la première phrase du segment repris. Ces phrases ainsi annotées dans leur contexte constitueront notre corpus d'entraînement.


We choose to work on the sentences p



%------------------------------------------------------------------------------
\subsubsection{Annotation generation procedure}
\label{}

The generation process aims at "automatically" annotating sentences from the source messages with segmentation information.
Figure~\ref{fig:procedureTrainingDataGeneration} describes the steps of the generation procedure at the global level. 
Each message from our corpus are tokenized and the sentences split. The quoted lines in the reply messages are identified based on the presence of a specific prefix at the beginning of the lines. 
Pair of source and reply messages are made up based on the \texttt{in-reply-to} meta data present in the email headers.
The word tokens are used to index the quoted lines and the sentences. 
Section~\ref{secalignmentmodule} describes our method to align the quoted sentences from the reply messages with the sentences from the source messages. 
Figure~\ref{fig:algoLabellingEachAlignedSentence} gives some precisions about the algorithm for labelling each aligned sentence with a segmentation instruction. 

\begin{figure}[ht!]
%\begin{enumerate}
%\item List the source and the reply messages
%\item 
\fbox {
    \parbox{\linewidth}{
For each pair of source and reply messages
\begin{enumerate}
\item Tokenize both messages in words and sentences
\item Identify % the tokens which are part of 
the quoted lines in the reply message
\item Identify the sentences which are part of the quoted text in the reply message
\item Align the sentences from the source message with the ones from the quoted text in the reply message 
%\item For each aligned sentence 
%\begin{enumerate}
\item Label each aligned source sentence in terms of its segmentation role (See~Figure~\ref{fig:algoLabellingEachAlignedSentence})
%\end{enumerate}
\item Add to the training data the labelled message made up by the sequence of labelled sentences %The sequence of labelled sentences makes up a labelled message which is add to the training data 
\end{enumerate}
}}

%\end{enumerate}
\caption{Procedure for generating the training data}
\label{fig:procedureTrainingDataGeneration}
\end{figure}


\begin{figure}[ht!]
%\fbox{
%\begin{enumerate}
%\item 
\fbox {
    \parbox{\linewidth}{
For each aligned source sentence %identified quoted sentence
 (sentence from the source message re-used in the reply message)
\begin{itemize}
\item if the sentence is surrounded by new content in the reply message, then label it \texttt{Start\&End}
%both the previous and the next sentences are part of the
\begin{itemize}
\item[$\bullet$] else if the sentence is preceded by a new content, then label it  \texttt{Start}
\begin{itemize}
\item[$\bullet$] else if the sentence is followed by a new content, then label it  \texttt{End}
\begin{itemize}
\item[$\bullet$] else label it  \texttt{Inside}
\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}
    }
}

%}
%\end{enumerate}
\caption{Algorithm for labelling each aligned sentence with a segmentation instruction}
\label{fig:algoLabellingEachAlignedSentence}
\end{figure}




%------------------------------------------------------------------------------
\subsubsection{Alignment module}
\label{secalignmentmodule}



For finding alignments between two given text messages, we use 
%an implementation of the % Implements a portion of the
% NIST align/scoring 
%algorithm to compare a reference string to a hypothesis string. 
a \textit{dynamic programming (DP) string alignment algorithm} \cite{sankoff:1983}. 
In the context of speech recognition, the algorithm is also known as the \textit{NIST align/scoring algorithm}. Indeed, it is widely used to evaluate the output of speech recognition systems by comparing the hypothesized text %(HYP) 
output by the speech recognizer to the correct, or reference % (REF) 
text. 
%In particular, it is used to compute the word error rate (WER) and the sentence error rate (SER).
%
The %``DP string alignment 
algorithm works by ``performing a global minimization of a Levenshtein distance function which weights the cost of correct words, insertions, deletions and substitutions as 0, 75, 75 and 100 respectively.
%
The computational complexity of DP is $0(NN)$.''
%    final static int MAX_PENALTY = 1000000;
%    final static int SUBSTITUTION_PENALTY = 100;
%    final static int INSERTION_PENALTY = 75;
%    final static int DELETION_PENALTY = 75;
%The alignment and metrics are intended to be, by default, identical to those of the \url{http://www.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm} NIST SCLITE tool.  
%The program sclite is a tool for scoring and evaluating the output of speech recognition systems. Sclite is part of the NIST SCTK Scoring Tookit. The program compares the hypothesized text (HYP) output by the speech recognizer to the correct, or reference (REF) text. After comparing REF to HYP, (a process called alignment), statistics are gathered during the scoring process and a variety of reports can be produced to summarize the performance of the recognition system.
%\url{http://www1.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm}



%CMU Sphinx
%Open Source Toolkit For Speech Recognition
%Project by Carnegie Mellon University
% of the performance of a speech recognition or machine translation system.



The Carnegie Mellon University provides an implementation of the algorithm in its speech recognition toolkit\footnote{Sphinx 4 \texttt{edu.cmu.sphinx.util.NISTAlign} %source code.
\url{http://cmusphinx.sourceforge.net}}.
%Implements a portion of the NIST align/scoring algorithm to compare a reference string to a hypothesis string.  It only keeps track of substitutions, insertions, and deletions.
We use an adaptation of it which allows to work on lists of strings\footnote{\url{https://github.com/romanows/WordSequenceAligner}} and not directly on strings (as sequences of characters).


%and other statistics available from an alignment of a hypothesis string and a reference string.

In comparison to the speech recognition and translation use cases, despite some noise, the compared text should include identical parts of the source one.



%------------------------------------------------------------------------------
\subsubsection{Restrictions}
\label{}

Focus on the first message of a thread and its reply messages to avoid noisy data due to several levels of quoted lines.

Restrict on short messages as an heuristic to filter out the long code trace message

Due to alignment complexity focus only on the first 25 000 tokens.

In source message, focus on part which is new ; in reply message, focus on part which is new + only the first? quoted level 
 


% -----------------------------------------------------------------------------
\subsection{Building the segmenter}


Our email speech act segmenter system is built around a linear-chain Conditional Random Field (CRF) classifier, as implemented in the sequence labelling toolkit Wapiti \cite{lavergne2010practical}. Each email is processed as a sequence and each sentence as an element of that sequence.

\subsubsection{Features for boundary detection}

The classifier uses features that capture graphic, orthographic, lexical and syntactic information about the sentence. Many of them are borrowed from related work in speech act classification \cite{qadir2011classifying} and email segmentation \cite{lampert2009segmenting}.

\subsubsection{Lexical and syntactic features}

\textbf{Ngrams:} we focus on the first and last three significant tokens in the sentence. Significance is determined by the number of occurrences of the token in the training corpus: terms with a frequency lower than \todo{fix me} 1/X are considered insignificant. 

If a sentence contains less than six significant tokens, the same token can be found in both triplets. For example, in the sentence \textit{``Have a good day !''}, the first three tokens would be \textit{``Have''}, \textit{``a''}, \textit{``good''} and the last three would be \textit{``good''}, \textit{``day''} and \textit{``!''}. If the sentence contains less than three significant tokens, missing values are replaced by a placeholder.

We define three individual features for the three unigrams, the two bigrams and the single trigram found in each of these sets. The features are the following: the unaltered form of the token (case-sensitive), the lemmatized form of the token (case-insensitive ; numbers present in the token are replaced by a special character) and the corresponding part-of-speech.

We use the Stanford Log-linear Part-Of-Speech Tagger for morpho-syntactic tagging \cite{toutanova2003feature}, and the WordNet lexical database to perform lemmatization \cite{miller1995wordnet}.

\textbf{Question words and interrogative ngrams:} one feature checks if a sentence begins with a ``wh*'' question word  (\textit{``who''}, \textit{``when''}, \textit{``where''}, \textit{``what''}, \textit{``which''}, \textit{``what''}, \textit{``how''}) or an ngram suggesting an incoming interrogation (e.g. \textit{``is it''} or \textit{``are there''}), and another one checks if the sentence merely contains such a word or ngram.

\textbf{Modals:} one feature indicates wether the sentence contains a modal (\textit{``may''}, \textit{``must''}, \textit{``shall''}, \textit{``will''}, \textit{``might''}, \textit{``should''}, \textit{``would''}, \textit{``could''}, and their negative forms).

\textbf{Plan phrases:} one feature looks for plan phrases (e.g. \textit{``i will''} or \textit{``we are going to''})

\textbf{Personal words:} three features check for first person, second person and third persons words, respectively (e.g. \textit{``we''}, \textit{``my''} and \textit{``me''} are recognized as first person words).

\textbf{First personal pronoun:} one feature records the first personal pronoun found in the sentence.

\textbf{First verbal form:} one feature records the tag of the first verbal form found in the sentence as classified by the Stanford Part-Of-Speech tagger ; that is an element of the Penn Treebank tag set \footnote{Alphabetical list of part-of-speech tags used in the Penn Treebank Project: \url{http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html}} (e.g. the feature \textit{``VBZ''} indicates a present tense verb in third person singular).

\subsubsection{Graphic features}

The following features' values are relative to other sentences. Four classes are defined for each feature: ``highest'' (top 25\%), ``high'' (top 50\%), ``low'' (bottom 50\%) and ``lowest'' (bottom 25\%).\newline

\textbf{Number of tokens:} the total number of tokens in the sentence, including insignificant ones.

\textbf{Number of characters:} the total number of characters in the sentence, including those in insignificant tokens.

\textbf{Average token length:} the average length of a token, including insignificant ones.

\textbf{Proportion of uppercase characters:} the proportion of uppercase characters in the sentence.

\textbf{Proportion of alphabetic characters:} the proportion of alphabetic characters in the sentence.

\textbf{Proportion of numeric characters:} the proportion of numeric characters in the sentence.

\subsubsection{Orthographic features}

\textbf{Number of greater-than signs:} the number of greater-than signs (``>''), also know as ``chevron'' symbols, in the sentence. Like previous features, this one is computed relatively to other sentences in the training set.

\textbf{Position:} the position of the sentence in the email.

\textbf{Question mark:} one feature checks if the sentence ends with a question mark, and another checks if it at least contains one.

\textbf{Colon:} one feature checks if the sentence ends with a colon, and another checks if it at least contains one.

\textbf{Semicolon:} one feature checks if the sentence ends with a semicolon, and another checks if it at least contains one.

\textbf{Early punctuation:} the last feature checks if the sentence contains any punctuation within the first three tokens of the sentence. This is meant to recognize greetings \cite{qadir2011classifying}.

